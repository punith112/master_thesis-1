\chapter{Analysis and Benchmark\label{cha:chapter6}}

\section{Ground Truth}\label{sub:ground truth}
To assess the quality of the localization algorithm, the true position of the robot needed to be obtained in order to do the comparisons and benchmarks with the position calculated by the algorithm. The true position of the robot or the so called \textit{ground truth} can not be obtained from the robot itself, since it does not have built in \gls{GPS} or other position tracking sensors. Moreover, the accuracy within centimeters is required for this purpose. 

The approach adopted in this paper is SSL-Vision \cite{zickler2010ssl}, the vision system used in RoboCup Small Size League to obtain the position of the robots. SSL-Vision requires a camera mounted on the ceiling, and a marker with specific pattern on top of the robot. By detecting the marker and the field through the ceiling camera, the ground truth can be obtained. For NAO robot, since its head could be scanning left and right, the marker can not be directly attached on its head, otherwise the robot's orientation obtained is not correct. To counter this, a plastic support is printed using 3D printer. As illustrated by \autoref{fig:collage}, the support is worn by the robot from the back, and the marker is attached on the top of the support.

\begin{figure}[h!]
  \centering
  \includegraphics[width=.7\textwidth]{sslvision-collage.png}
  \caption{The 3D printed support and the pattern marker}
  \label{fig:collage}
\end{figure}

In the SSL-Vision software \cite{sslvision_yuan}, first set the field size, robot height, camera height and the corners of the field to calibrate the camera, so a point in the image plane can be mapped to the coordinate of the global frame. Then the colors in the field and the colors from the marker needed also to be calibrated. Shown in \autoref{fig:calibration} is the visualization result after calibration. When the marker is detected by SSL-Vision, the coordinate of the robot position in global frame will be broadcasted via network. The detected robot position is drawn in the field GUI in \autoref{fig:position}.\\

\begin{figure}[h!]
        \centering
        \begin{subfigure}[h]{0.59\textwidth}
                \includegraphics[width=\textwidth]{gt2.png}
                \caption{calibration result}
                \label{fig:calibration}
        \end{subfigure}%
        ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
          %(or a blank line to force the subfigure onto a new line)
        \begin{subfigure}[h]{0.41\textwidth}
                \includegraphics[width=\textwidth]{gt1crop.png}
                \caption{position in field}
                \label{fig:position}
        \end{subfigure}%
	\caption{SSL-Vision color and camera calibration result (a), robot position result (b)}
	\label{fig:sslVision result}
\end{figure}


\noindent\textbf{Disadvantages of SSL-Vision}
\begin{itemize}
  \item The system highly depend on the light of the environment, once the surrounding light changes, the color metrics need to be recalibrated. 
  \item If the marker is printed using normal paper, it may cause reflection at certain angle from the view point of the camera, then the pattern can not be detected. For this reason, fuzzy materials are specially chosen to manually create the marker. 
  \item The system can not detect the pattern when the robot is fallen.
\end{itemize}

\section{Logging Perception and Ground Truth}
\label{sub:Logging Perception and Ground Truth}
For the purpose of debugging and benchmark, the robot can stores the perception as log for future replay. The log contains the necessary data needed to re-run the localization algorithm on another computer. Within the log, it includes vision results, odometry, \gls{IMU}, sonar data, time stamp, robot posture, etc. In order to benchmark the quality of the localization algorithm result, the ground truth data needed to be stored as well, and when the log is replayed, the ground truth data should be synchronized with the perception log. The solution for this is to store the broadcasted ground truth from SSL-Vision at the same of recording the perception, and the ground truth become part of the perception log. The replayed perception log with ground truth is already illustrated in \autoref{fig:landmarkRobotFrame}, in which the ground truth position indicated by red, calculated position in cyan, mirrored calculated position in pink.

%\begin{figure}[h!]
%  \centering
%  \includegraphics[width=.7\textwidth]{logagent.png}
%  \caption{perception log replayed with ground truth using particle filter localization (ground truth (red), calculated position (cyan), mirrored calculated position (pink))}
%  \label{fig:logagent}
%\end{figure}





