\chapter{Multi-Hypotheses Kalman Filter Localization\label{cha:chapter5}}
While the Kalman filter can only deal with uni-modal probability distribution, it does not suffice to handle the ambiguous landmarks that occur in robot's observation, which requires a multi-modal distribution. Therefore, a multi-hypotheses Kalman filter is adapted to handle the ambiguous situations by describing the robot position in the field by a Gaussian sum distribution.
The problem of multi-hypotheses Kalman filter lies mainly in the domain of when and where to add new hypothesises into the Gaussian sum distribution, as well as when to prune or merge certain hypotheses to restrain the number of hypotheses within a limit, so it does not consume too much of the computation resources.


\section{Hypothesis Model Weighting}
As illustrated in \autoref{sub:mmkalman}, each normal probability distribution from the Gaussian sum distribution is represented as \autoref{eq:mmkalman}. In addition to uni-modal Gaussian distribution, the weight $\alpha_i$ has to be determined for each Gaussian distribution model $i$ in the Gaussian sum distribution. The weight, at the same time, illustrates the quality of the state hypothesis. Possible update method like \autoref{eq:weightupdate} has been proposed in \cite{alspach1972nonlinear}. However, this update method is only suitable for landmarks with known correspondence. If the correspondence is unknown or ambiguous, like in our case, the ``T'' junctions, the expected observation $z\widehat{}_i$ can not be determined. 

In this thesis, a voting buffer is used to measure the weight of each model. The voting buffer is constructed by a \gls{FIFO} circular buffer of size $60$. The basic idea is to vote $1$ to the buffer when the observed landmark is matched, and $0$ when not matched. The matching of landmark correspondence is using the nearest neighbor algorithm with threshold discussed in \autoref{subsub:landmarkco}. 
The advantage of using a circular buffer is that, after $60$ observed landmarks, regardless matched or not, the old voting in the buffer will be flushed and will not be counted. In other words, it tries to approximate the current robot state by keeping the memory of the most recent history. The model weight is determined by the average value of the voting buffer. Therefore, the more matches with landmarks the Kalman model makes, the higher weight it will have. 

Unlike the implementation of particle filter that the total number of particles are fixed, in multi-hypothesis Kalman filters, the number of hypothesis model is dynamic. The adjustment made here is that the weights of all the Gaussian models do not add up to 1, instead they each behave independently. So the weights of the existing hypothesis models will not be affected by the newly generated ones.

As discussed in subsection \ref{subsub:landmarkco}, some landmarks are unique landmarks, \ie{} center circle, and some are ambiguous landmarks, \ie{} junctions and lines. To depict the quality of the robot localization state, the vote should depend only on the globally unique landmarks instead of ambiguous landmarks. Assume a scenario, where the robot is not moving and constantly observing a ``T'' junction, and the ``T'' junction is perfectly matched with its nearest neighbor in the field. In this case, the state of the robot position is local optimal. The weight of the model will keep increasing and reach 1, but this weight is not truly describing the quality of localization state in global. 

To better express the localization state globally, in the localization algorithm, landmarks are classified differently to update the weight. In observation, center circle with/without orientation and penalty area are treated as unique landmarks, they can directly vote 1 to the voting buffer when the threshold requirement in the nearest neighbor algorithm is satisfied, or vice versa. 

On the other hand, ``L'', ``T'', ``X''junctions are classified as non-unique landmarks, the voting buffer can be voted by 1, only when at least two junctions are matched, and in addition they must each belong to different junctions in the field. The junctions under consideration do not distinguish ``L'', ``T'' or ``X'', and they can come from different observation frames, as long as there is no failure match (beyond threshold) in between. By using the combination of the different observations of junctions, we assume it represents a global unique landmark, thus helping to overcome the local optimal problem. While the requirement of voting positive using junctions is strict, the condition of voting 0 is the same as the unique landmarks, \ie{} when a failure match happens for the junction, a 0 will be voted to the buffer.  

For the observed line landmarks, they are currently not contributing to the voting buffer. To utilize the lines, certain feature structures need to be extracted from them, in order to use the same strategy above to update the voting buffer. However, the extraction of other features out of the lines is not an easy task, further work may be required in this regard in the future. 
%summing up the values in the voting buffer and calculate the average.


\section{Landmark Based Resampling}\label{sec:resample}

Similar to the augmented particle filter's \cite{thrun2005probabilistic} sensor reseting step to recover the situation of robot getting kidnapped, multi-hypotheses Kalman filter uses sensor reseting based on landmarks to recover from position tracking failure. Assume uni-modal Kalman filter for position tracking, the filter can lose track of the robot's position when the robot is hit by another robot which results in an error in robot's orientation; or the robot is kidnapped by a referee during manual replacement, etc. Augmented particle filter initiates the sensor resetting step to generate random particles when the fluctuation of the weights from the particles is high, multi-hypotheses Kalman filter designed in this thesis will start resampling when an observed landmark fails to match the one on the field. Here, a correspondence match failure is regarded as a signal for potential loss of position tracking. 

The resampling is achieved by calculating all the possible poses of the robot with respect to the observation of the landmark. The landmarks which can trigger resampling are the landmarks with orientation, \ie{} center circle with center line and all kinds of junctions. The landmarks without orientation like lines, center circle without center line and penalty area can generate infinite possible robot positions, therefore currently they are not used for resampling. The problem of calculating the possible poses can be formulated as follows:

Given an observed landmark $l_R = (x_R, y_R, \theta_{R})$ in robot frame, and assume its correspondent landmark $l_G = (x_G, y_G, \theta_{G})$ in physical world frame, the corresponding robot pose in physical world frame is what is needed to be calculated. The calculation concerns mainly with the coordinate frame transformation which can be described by homogeneous transform matrix. 

A homogeneous transform matrix in our context is a $3 \times 3$ matrix. It is structured by a $2 \times 2$ rotation matrix $R_B^A$ and a $2 \times 1$ translation matrix  $P_B^A$ denoted in \autoref{eq:homomat}.
\begin{equation}
\label{eq:homomat}
T_B^A =
\begin{bmatrix}
R_B^A & P_B^A \\
\bf{0}   & 1 
\end{bmatrix}
\end{equation}

The sub and super-script in $R_B^A$ indicate that it is the rotation of frame $B$ relative to frame $A$. Translation matrix  $P_B^A$ denotes the translation of the origin of frame $B$ in frame $A$.
In the following equations, we represent the robot pose in physical world frame in the form of  homogeneous transform matrix as $T_R^G$, landmark in robot frame as  $T_L^R$, landmark in physical world frame as $T_L^G$.
According to \textit{Composition Rule for Homogeneous Transformations}, the transformation between $T_R^G$, $T_L^R$ and $T_L^G$ can be described in \autoref{eq:trans}.
\begin{equation}
\label{eq:trans}
T_R^G \cdot T_L^R=T_L^G
\end{equation}

To obtain $T_R^G$, we multiply $(T_L^R)^{-1}$ from the right for both side of the equation, then obtain \autoref{eq:reverseTrans}.

\begin{equation}
\label{eq:reverseTrans}
	T_R^G=T_L^G\cdot (T_L^R)^{-1} 
\end{equation}

Substituting the homogeneous transform matrix using \autoref{eq:homomat}, and calculating the inverse of matrix, results in the following:
\begin{equation}
\label{eq:reverseTrans2}
	T_R^G=
\begin{bmatrix}
R_L^G & P_L^G \\
\bf{0}   & 1 
\end{bmatrix} \cdot
\begin{bmatrix}
  (R_L^R)^\top & -(R_L^R)^{\top} P_L^R \\
\bf{0}   & 1 
\end{bmatrix}
\end{equation}


\begin{equation}
\label{eq:reverseTrans3}
	T_R^G=
\begin{bmatrix}
  R_L^G(R_L^R)^\top & -R_L^G(R_L^R)^{\top} P_L^R +  P_L^G\\
\bf{0}   & 1 
\end{bmatrix}
\end{equation}

By using the rotation matrix representation stated in \autoref{eq:rot}, the rotation matrix and translation matrix in $T_R^G$ is calculated in  \autoref{eq:reverseTrans4} and \autoref{eq:reverseTrans5}.
\begin{equation}
\label{eq:reverseTrans4}
	R_R^G=
	R_L^G(R_L^R)^\top =
  \Omega(\theta_{G} - \theta_{L}) 
\end{equation}

\begin{equation}
\label{eq:reverseTrans5}
	P_R^G=
	-R_R^G P_L^R +  P_L^G=
   -\Omega(\theta_{G} - \theta_{L}) \cdot
\begin{bmatrix}
  x_R\\
  y_R
\end{bmatrix}
+
\begin{bmatrix}
  x_G\\
  y_G
\end{bmatrix}
\end{equation}

Therefore, given the correspondence of $l_R$ and $l_G$,  the robot x-y position is $P_R^G$ and orientation is $\theta_{G} - \theta_{L}$. The number of possible robot poses generated depends on the occurrence of the landmarks in the field. For example, a mismatch of a ``T'' junction would trigger resampling which would generate 14 possible robot poses. The weight for the newly generated hypothesis model is 1 divided by the number of occurrences of the landmarks in the field. So, in the case for resampling by ``T'' junction, the weight for the new hypothesis model is $1/14 = 0.0714$. However, the model resampled by center circle is an execution as only one model will be generated. The weight of this model will be directly proportional to the detection confidence of the center circle.

\subsection{``L'' Junction Look Up Table}
\label{sub:Junction Look Up Table}
A special case worths discussing is the observation of the ``L'' junctions, as there are 36 occurrences of ``L'' junctions in the field, a match failure can resample as much as 36 possible robot positions, the weight for the newly generated hypothesis model will be $1/36=0.027$ which is extremely low. Such low weight model can be easily pruned in the pruning step which we will discuss in \autoref{sec:pruning}. However, due to the large number of occurrences of ``L'' junctions, the possibility of observing more than one ``L'' junctions at the same frame is also high. When more than one ``L'' junctions are observed in one frame, the number of possible positions can also be reduced. Given the ``L'' junctions observed, the implementation to generate possible positions due to multiple ``L'' junctions is described in the following steps:

\begin{enumerate}
  \item Take one observed ``L'' junction, use \autoref{eq:reverseTrans4} and \autoref{eq:reverseTrans5} to generate 36 possible robot positions based on all the ``L'' junctions in the field. 
  \item Take another observed ``L'' junction, at each robot position generated in Step 1, project the ``L'' junction to the physical world frame.
  \item Check if at the place where the observed ``L'' junction is projected, there exists an  ``L'' junction in the field. If so, this generated robot position is valid, otherwise it is an invalid position.
  \item If there are remaining ``L'' junctions in observation, steps from Step 2 are repeated. Otherwise, the possible robot positions which are valid are returned.
\end{enumerate}

To speed up the computation, Step 3 above is implemented using a pre-computed look up table. Given a pose $(x_l, y_l, \theta_l)$ of the ``L'' junction in physical world frame,  the look up table will return boolean value, \ie{} true or false, depending on whether in the vicinity of pose $(x_l, y_l, \theta_l)$, there exists an ``L'' junction. Although it is a 3-dimensional look up table, the resolution can be configured coarse, it will not consume too much memory. In return, the checking of 36 ``L'' junctions in physical world frame can be done together at once. A visualization example of the look up table is illustrated in \autoref{fig:lcornerLUT}. Since it is a 3-dimensional look up table, \autoref{fig:lcornerLUT} only shows the look up table when the angle dimension is at \SI{90}{\degree}. It means, if given an ``L'' junction in physical world frame with angle being \SI{90}{\degree}, only the ``L'' junctions which fall into the bright area is valid. %The correctness can be verified by checking in correspond with \autoref{fig:ljunctions}.

\begin{figure}
\begin{center}
	\includegraphics[width=0.8\textwidth]{fieldwithLcornerslut.png}
\end{center}
\caption[``L'' junction look up table]{``L'' junction look up table with angle dimension at \SI{90}{\degree}. Bright parts indicate true, dark parts indicate false}
\label{fig:lcornerLUT}
\end{figure}

To further reduce the number of sampled positions by ``L'' junction, we retain only the positions which are close enough to the last robot position. With the filtering of the positions generated by ``L'' junctions, the weight of the sampled position is set to be the same as the ones generated by ``T'' junctions.

\section{Best Hypothesis Model and Confidence}\label{sec:robotpose}
In multi-hypothesis Kalman filter, there are multiple hypothesis models to form the possibility distribution. From the robot position probability distribution, one position $(x_{r}(t), y_{r}(t), \theta_{r}(t))$
has to be determined as the end result of localization algorithm. In the algorithm designed, the position is chosen to be the mean of the ``best'' hypothesis model in the probability distribution. The  ``best'' hypothesis model should satisfy the following two criteria:
\begin{itemize}
  \item Firstly, the hypothesis model should be globally best, which can be indicated by the weight of the model, the one with the highest weight is believed to be globally the best.
   \item Secondly, when multiple models have the same weights, then the quality of local belief is compared which can be indicated by the covariance of the Gaussian model. The one with the lowest covariance is believed to be the best.
\end{itemize}

Covariance describes the confidence of the belief of the current Gaussian model. To compare the covariance value between the models, it is re-structured as $Cov$ in \autoref{eq:coveq}. $Cov$ is the sum of the diagonal elements of the covariance matrix. Since the error in orientation can cause more negative influence on robot position, \ie{} the larger the error in orientation, the further the projected observed landmark will be away from its global correspondence, thus harder to match. Therefore, the variance value for orientation is doubled to have a higher weight in comparison.
\begin{equation}
\label{eq:coveq}
Cov = Cov_x + Cov_y +2*Cov_{\theta}
\end{equation}

When the ``best'' model is chosen, its covariance is also set to be the covariance of the robot position, and the weight is set to be the confidence for the position.

\section{Model Pruning}\label{sec:pruning}
While the resampling step generates hypothesis models into the Gaussian sum distribution, pruning step is also necessary to remove the hypothesis models which are redundant or have little contribution to the whole distribution.

\subsection{Pruning by Weight}
\label{sub:Pruning by Weight}
When the weight of hypothesis model is lower than a certain threshold, this model is considered to have little contribution to the distribution, so that it can be removed. Moreover, the maximum number of models is limited to a number $N$ set by the localization algorithm. Once the maximum number of models is exceeded, the models are sorted by weight from high to low in a list. Only first $N$ models in the list will remain, the others will be deleted.

\subsection[Pruning by Mahalanobis Distance]{Pruning by Mahalanobis Distance \cite{de2000mahalanobis}}
\label{sub:Prunning Mahalanobis Distance}
When the hypothesis models are close enough to each other, in other words, they represent almost the same probability distribution, they could also be merged into one. One way is to apply Euclidean distance directly between the mean of the models to calculate the distance as shown in \autoref{eq:euclidean}. $\mu_1$ and $\mu_2$ represent the mean of two different Gaussian distributions.

\begin{equation}
\label{eq:euclidean}
D_{euclidean} = \sqrt{(\mu_1 - \mu_2)^T(\mu_1 - \mu_2)}= \sqrt{(x_{1}-x_{2})^2 + (y_{1}-y_{2})^2 + (\theta_{1}-\theta_{2})^2}
\end{equation}
However, the drawback of using Euclidean distance is that the covariance information of the distribution is not utilized. In this thesis, 
the method used to measure distance between two hypothesis models is an adapted version of Mahalanobis distance. Mahalanobis distance is defined as follows in \autoref{eq:mahalanobis} \cite{de2000mahalanobis}, which uses covariance as one factor to calculate the distance. In \autoref{eq:mahalanobis}, $x$ is the observation, $\mu$ is the mean of the distribution and $S$ is the covariance matrix.
\begin{equation}
\label{eq:mahalanobis}
D_M(x) = \sqrt{(x - \mu)^T S^{-1} (x-\mu)}
\end{equation}

The modified Mahalanobis distance to measure distance between two Gaussian hypothesis models is defined in \autoref{eq:mahalanobismod}.
\begin{equation}
\label{eq:mahalanobismod}
D_{mahalanobis} = \sqrt{((\mu_2 - \mu_1)^T S_1^{-1} (\mu_2-\mu_1) + (\mu_1 - \mu_2)^T S_2^{-1} (\mu_1-\mu_2)) \cdot 0.5}
\end{equation}

An example is illustrated in \autoref{fig:gaussians}, although the Euclidean distance between the mean of the two Gaussian distributions are close ($D_{euclidean}=0.5$), the Mahalanobis distance is relatively larger ($D_{mahalanobis}=1.77$) due to the significant difference between their deviations. As a result, Mahalanobis distance is more suitable for describing the model distance than Euclidean distance.


\begin{figure}[!htbp]
\begin{center}
  \input{./tikz/gaussian.tikz}
\end{center}
\caption{Visualization of two Gaussian distributions}
\label{fig:gaussians}
\end{figure}

%\begin{figure}[tbh]
%\begin{center}
%	\includegraphics[width=0.65\textwidth]{twogaussian.png}
%\end{center}
%\caption{Visualization of two Gaussian distributions}
%\label{fig:gaussians}
%\end{figure}

To prune hypothesis models, the Mahalanobis distance is calculated between each pair of the models. If the Mahalanobis distance is under certain threshold, the two models are considered to be close to each other, and the one with lower weight will be removed. If both weights are the same, the model with higher covariance will be removed.


\subsection{Pruning by Distance to Best Model}
\label{sub:Pruning by Distance to Best Model}

As we discussed in \autoref{sec:robotpose}, the model whichever is the ``best'' is chosen to represent the robot position. To further prune hypothesis models, the models which are very close to the ``best'' model are also removed. This distance is measured simply by Euclidean distance and the threshold is set to be a small value \SI{2}{\cm}.

