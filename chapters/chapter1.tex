\chapter{Introduction\label{cha:chapter1}}

Robot Soccer World Cup, known as RoboCup, is an annual international robotics competition conducted since 1997. It aims to foster research and development of robotics and \gls{AI}, by offering a public appealing but challenging competition. RoboCup consists of five major competition domains, they are RoboCup Soccer, RoboCup Rescue, RoboCup@Home, RoboCup Logistics and RoboCup Junior. Currently the RoboCup Soccer includes several soccer leagues to cover difference research challenges. The main concern in this thesis is the \gls{SPL} under the sub-category of RoboCup soccer, in which all the teams use identical humanoid robot NAO that is manufactured by Aldebaran Robotics. The robots should operate fully autonomously without external control. 
The research regarding RoboCup \gls{SPL} has been actively conducted under various topics. DAInamite, a team from DAI-Labor, TU-Berlin, is dedicated in advancing robot technology; the team has continuous research on humanoid robot NAO and their first participation in the world championship in the \gls{SPL} was in RoboCup 2013 in Eindhoven, reaching the quarter finals. The code base from DAInamite consists of several modules including motion, vision, behavior, localization, etc, which makes the NAO robot fully functional and competitive in the RoboCup game.
The implementation of the localization algorithm proposed in this thesis will be based on the current software infrastructure of DAInamite. 
%In addition to \cpp{}, Python is mainly used in the team's code.
%The main advantage for using Python is having a flexible programming language for rapid development of new ideas and prototypes.
%The time-critical components for motion, and vision are implemented in \cpp{}. The remaining modules such as localization,  behavior, and ball-tracking are implemented in Python.

\section{Motivation\label{sec:moti}}
Localization awareness is a central aspect for many pervasive computing applications, especially for autonomous robots playing soccer. Just like human, the robots need to know where themselves are on the field when playing soccer, in order to make decisions and undertake actions. The high level decision making depends highly on the accuracy of the location of the robot, e.g. moving towards a particular direction to split the defense of the defender, or kicking the ball to the goal, or distinguishing the opponent's goal on its own. If the result of localization is inaccurate, it will not only curtail the performance of other algorithms like ball tracking and goal saving, but also prohibit developing advanced techniques for competitive enhancement like opponent modeling or passing the ball to teammates. 

%Because, for example, if the ball's position has been correctly detected, due to the inaccuracy of the self-localization of the robot, it perceives itself to be next to the ball, although it is not, so the following ball kicking decision made by the high level robot engine will have no effect. \autoref{fig:robot_perception} illustrates how the robot perceives itself at one particular time.
%\begin{figure}[h]
%  \centering
%  \includegraphics[width=0.6\textwidth]{robot_perceive.png}
%  \caption{Robot perception of its location at one particular time~\cite{Quinlan2010}}
%  \label{fig:robot_perception}
%\end{figure}

In many other applications like self driving car, many sensors including the \gls{GPS}, laser scanners, radar or high end 3D cameras are used to help accomplish the localization task. 
However, for the NAO robot, with limited number of sensors and restricted computational capability of the processing unit, the localization problem becomes particularly challenging. The robot is able to get odometry information from the body kinematics and \gls{IMU} to calculate the supposed walking distance, and using this to help predict its location. 
Although the odometry information is the most direct measurement for the input of localization calculation, inherited systematic errors like asymmetry of the installation of the joint motors will cause the robot to constantly produce offset in walking, or unpredicted environment factors like foot slipping on the ground, bump into obstacles. 
The accumulated odometry errors throughout a time period will result in unacceptable localization result. 

Besides odometry information, the NAO robot can also use its two \gls{HD} cameras to sense the surrounding environment, but without depth information. Since the cameras have \SI{60.9}{\degree} horizontal field of view and \SI{47.6}{\degree} vertical field of view, the robot can only get local partial perception of the field at any given time.
%, thus activly sensing the enviroment is necessary for the robot.
With image processing, landmarks or features can be extacted from the images as another input for localization calculation. However, due to the non-uniqueness of most of the landmarks in the \gls{SPL} field and false positive results from image processing, the landmarks become severely ambiguous. On the other hand, the image may also be blurred due to the motion of the robot, and the environment is dynamically changing as the other moving robots may occlude the landmark. These challenges impose significant difficulties not only in detecting the features from the noisy image, but also the knowhow of employing ambiguous landmarks for localization. 


Furthermore, the soccer field itself is symmetrically structured, which means the two halves of the field are the same. To counter this problem, normally features outside of the field need to be considered to differentiate one side from the other.
Not to mention,  NAO robot has limited computation power, which requires the localization algorithm to be computationally efficient and not to affect other critical modules like motion which have higher execution priorities.




\section{Problem Statement}
\subsection{Robot Hardware}\label{sub:hardware}
The robot used in this thesis for localization algorithm development is NAO V4 robot from Aldebaran Robotics. The robot is 573 mm in height, 275 mm in width. The body construction and the equipped sensors are illustrated in \autoref{fig:nao body construction}. Also, the robot has one 2-axis gyrometer and one 3-axis accelerometer inside the body, a \gls{FSR} on each foot bottom, which is not shown in \autoref{fig:nao body construction}.

\begin{figure}[h!]
  \centering
  \includegraphics[width=.8\textwidth]{nao_h21_pres.png}
  \caption[Body construction of NAO V4.]{Body construction of NAO V4. \cite{NAOBody}}
  \label{fig:nao body construction}
\end{figure}


The two cameras are placed on the face, each camera can capture image of resolution up to $1280 \times 960$@30fps. %The opening angles of the camera are shown in \autoref{fig:nao cameras construction}.

% \begin{figure}[h!]
%   \begin{subfigure}[b]{0.5\textwidth}
%     \includegraphics[width=\textwidth]{hardware_camera_lateral.png}
%     \caption{camera vertical angle}
%     \label{fig:camera1}
%   \end{subfigure}
%   \begin{subfigure}[b]{0.46\textwidth}
%     \includegraphics[width=\textwidth]{hardware_camera_top.png}
%     \caption{camera horiontal angle}
%     \label{fig:camera2}
%   \end{subfigure}
%   \caption{Cameras of NAO V4}
%   \label{fig:nao cameras construction}
% \end{figure}

The robot runs a Gentoo version of Linux and the mother board resides in the head of the robot. The specification of the mother board is:
\begin{itemize}
  \item ATOM Z530 1.6 GHz CPU \footnote{It is a single core processor, with Intel Hyper-Threading technology}
  \item 1 GB RAM
  \item 2 GB Flash memory
\item 8 GB Micro SDHC
\end{itemize}

\subsection[Standard Platform League Field]{\gls{SPL} Field}
Every year the rules of the \gls{SPL} are modified on the basis of the old ones to make them closer to the rules of real soccer game and at the same time increase the difficulty levels of the game. Significant changes include the field size being enlarged from $6m \times 4m$ to $9m \times 6m$ in 2013, and the color of goal posts become white instead of yellow in 2015. The schematic diagram of the soccer field and corresponding dimensions is depicted in \autoref{tab:field}.

\begin{table}[h]
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{lllllll}
\multicolumn{7}{c}{\includegraphics[width=.95\textwidth]{field.png}}\\
\multicolumn{1}{|l|}{ID} & \multicolumn{1}{l|}{Description}       & \multicolumn{1}{l|}{Length (in mm)} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{ID} & \multicolumn{1}{l|}{Description}            & \multicolumn{1}{l|}{Length (in mm)} \\ \cline{1-3} \cline{5-7} 
\multicolumn{1}{|l|}{A}  & \multicolumn{1}{l|}{Field length}      & \multicolumn{1}{l|}{9000}           & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{E}  & \multicolumn{1}{l|}{Penalty area length}    & \multicolumn{1}{l|}{600}            \\ \cline{1-3} \cline{5-7} 
\multicolumn{1}{|l|}{B}  & \multicolumn{1}{l|}{Field width}       & \multicolumn{1}{l|}{6000}           & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{F}  & \multicolumn{1}{l|}{Penalty area width}     & \multicolumn{1}{l|}{2200}           \\ \cline{1-3} \cline{5-7} 
\multicolumn{1}{|l|}{C}  & \multicolumn{1}{l|}{Line width}        & \multicolumn{1}{l|}{50}             & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{G}  & \multicolumn{1}{l|}{Penalty mark distance}  & \multicolumn{1}{l|}{1300}           \\ \cline{1-3} \cline{5-7} 
\multicolumn{1}{|l|}{D}  & \multicolumn{1}{l|}{Penalty mark size} & \multicolumn{1}{l|}{100}            & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{H}  & \multicolumn{1}{l|}{Center circle diameter} & \multicolumn{1}{l|}{1500}           \\ \cline{1-3} \cline{5-7} 
\multicolumn{1}{|l|}{}   & \multicolumn{1}{l|}{}                  & \multicolumn{1}{l|}{}               & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{I}  & \multicolumn{1}{l|}{Border strip width}     & \multicolumn{1}{l|}{700}           
\end{tabular}
\end{adjustbox}
\caption[Schematic diagram of the soccer field]{Schematic diagram of the soccer field (not to scale) and corresponding dimensions in
  mm. Note that measurements on this diagram are made to the center of lines. \cite{Committee2013}}
\label{tab:field}
\end{table}
\subsection{Problem Formulation}\label{sub:problem}
In the robotic localization problem, the algorithm is mainly concerned with estimating the ``state'' of the robot. The ``state'' in the context of the RoboCup \gls{SPL} refers to the location (2D Cartesian coordinate) and the orientation of the robot in the physical world. In this case the state to be estimated can be represented as a 3 dimensional vector $x(t)$ as follows:
\begin{center}
$x(t) =
 \begin{bmatrix}
  x_{r}(t) \\
  y_{r}(t) \\
  \theta_{r}(t) 
 \end{bmatrix} $ \\
\end{center}
where ($x_{r}(t)$, $y_{r}(t)$) denote the Cartesian coordinates and $\theta_{r}(t)$ is the orientation of the robot at time $t$. As illustrated in \autoref{fig:worldframe}, the coordinate system of physical world frame is defined with its origin located at the center of the field, and its positive x-axis axle pointing to the opponent's goal.
\begin{figure}[h]
  \centering
  \begin{tikzpicture}[
     axis/.style={very thick, ->, >=stealth'},
    ]
    \node[anchor=south west,inner sep=0] (image) at (0,0) {\includegraphics[width=0.8\textwidth]{globalcoordinates_crop.png}};
    \begin{scope}[x={(image.south east)},y={(image.north west)}]
           % axis
      \draw[axis] (0.178,0.29) coordinate (O) -- (0.8,0.29) coordinate(x) node(xline)[right]
      {$x$};
      \draw[axis] (O) -- (0.178,0.8) coordinate(y) node(yline)[left] {$y$};
       % \draw[red,ultra thick, dashed, rounded corners] (0.179,0.59) rectangle (0.459,0.53);
      %\draw[dashed] (O) -- (0.414, 0.508) coordinate(C);
      \draw[dashed] (0.414+0.1, 0.508) coordinate(yy) -- (0.178, 0.512) coordinate(Cy) node()[left] {$y_{r}$};
      \draw[dashed] (0.414, 0.508+0.1) coordinate(xx) -- (0.414, 0.29) coordinate(Cx) node()[below] {$x_{r}$};

      \draw[dashed] (0.414, 0.508) coordinate(C) -- (0.4968, 0.58) coordinate(Ctheta); 
      \draw (C)+(0.1,0.04) node() {$\theta_{r}$};	
      \draw pic[ draw=orange, ->, thick, angle eccentricity=1.2, angle radius=0.8cm]
      {angle=yy--C--Ctheta};

      \draw[dashed, ->, >=stealth'] (1.1, 0.622)  coordinate (T)  -- (0.936, 0.352); 
      \node[above, text width = 2cm, align=center] at (T) {opponent's goal};
    \end{scope}
  \end{tikzpicture}
  \caption{The defined coordinate system of physical world frame}
  \label{fig:worldframe}
\end{figure}

For robots in \gls{SPL}, the localization is intended to achieve the following tasks:
%the aim of localization can be categorized as the following tasks:
\begin{itemize}
  \item Global Localization: it happens at the beginning of the game, where the robot has to localize itself without the knowledge of its initial position.
  \item Position Tracking: it assumes that the initial position of the robot is known, and the position tracking can be achieved by accommodating the noise from motion and measurements.
  \item Kidnapped robot: the robot can be kidnapped and teleported to another position in the game. The problem is similar to global localization, except that the robot might believe it knows where it is while it does not.
    %still have the old belief of the position which is wrong.
\end{itemize}
As stated in \autoref{sec:moti}, the environment the robot resides in is inherently unpredictable, the sensors are limited in what they can perceive, the joint motors are also to some extent unpredictable. Hence, a probabilistic representation is used to describe the uncertainty of the robot's location, the probability distribution over the state $x(t)$ is called belief, written as $Bel(x_{t})$.

In order to estimate the state $x(t)$ and the belief $Bel(x_{t})$, localization algorithm takes the detected objects from vision in the field as one of the inputs. The DAInamite's vision module can detect yellow goal post, center circle, penalty area, lines in the field and boundary of the field, and by projecting the landmarks from the image frame to the robot's local frame, distances to the robot can be estimated. Furthermore, the odometry information is also fed into the localization algorithm. The odometry of the robot is obtained from the motion module by calculating the body kinematics, given that the robot has at least one foot placed on the ground.
\section{Thesis Outline\label{sec:outline}}

The rest of the thesis is structured as follows:
%\\
%\\
%\noindent This Master thesis is separated into 7 chapters.
\\
\\
\textbf{Chapter \ref{cha:chapter2}} describes the background and related work concerned to the fundamentals of Bayes theories and localization methods developed for robots in RoboCup, as well as the current software architecture from the team DAInamite, to which the localization algorithm will be integrated. 
\\
\\
%\textbf{\autoref{cha:chapter3}} This chapter briefly introduces the current software architecture from team DAInamite, to which the localization algorithm will be integrated.  
%\\
%\\
%\textbf{\autoref{cha:chapter4}} This chapter describes the current DAInamite software architecture in NAO robot for RoboCup, and how localization is related to other modules like motion and vision. 
\textbf{Chapter \ref{cha:chapter4}} explains the motion model and sensor model designed for \gls{EKF} based localization. It also illustrates the strategies to find landmark correspondence based on ambiguous observations. 
\\
\\
\textbf{Chapter \ref{cha:chapter5}} describes the design of multi-hypotheses Gaussian models which encapsulate a \gls{EKF} in each model. It explains the mechanism of resampling and pruning step to maintain a multi-modal probability distribution.
\\
\\
\textbf{Chapter \ref{cha:chapter6}} comprehensively analyses the functionality, accuracy and efficiency benchmarks of different localization algorithms.
\\
\\
\textbf{Chapter \ref{cha:chapter7}} summarizes the thesis with a conclusion and gives an outlook about the possible future work in this regard.
\\
\\
